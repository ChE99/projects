{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from Emails - Part 2 of 2\n",
    "The first part created the initial file after going through all the emails in inbox. The second part appends to the initial file after extracting information from emails between the current code execution date and when the latest file was created. Additionally, the code deletes older files in the destination path, creates visualizations in Plotly, and combines the plots in a basic dashboard in Dash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import win32com.client\n",
    "import re\n",
    "import time\n",
    "import dateutil.parser\n",
    "from dateutil import parser\n",
    "from dateutil import relativedelta\n",
    "from datetime import datetime\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from plotly import tools\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Latest File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the latest xlsx file.\n",
    "dates = []\n",
    "dest_path = os.getcwd() + '\\\\'\n",
    "for file in os.listdir(dest_path):\n",
    "    # Extract the date from the file's name.\n",
    "    date_file_text = re.search(r'Report_(.*?).xlsx', file)\n",
    "    if date_file_text != None:\n",
    "        # Extract the date string from the match object.\n",
    "        date_file_str = date_file_text.group(1)\n",
    "        # Convert to date format.\n",
    "        date_file_dtf = datetime.strptime(date_file_str, '%m_%d_%Y')\n",
    "        # Append to dates list.\n",
    "        dates.append([date_file_dtf, date_file_str])\n",
    "        # Sort by latest date.\n",
    "        dates_sort = sorted(dates, reverse=True)\n",
    "        # Match latest date with file name.\n",
    "        if dates_sort[0][1] in file:\n",
    "            latest_file = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the latest xlsx file.\n",
    "df_file_summary = pd.ExcelFile(latest_file).parse(0)\n",
    "df_file_preval = pd.ExcelFile(latest_file).parse(1)\n",
    "df_file_errors = pd.ExcelFile(latest_file).parse(2)\n",
    "df_file_certs = pd.ExcelFile(latest_file).parse(3)\n",
    "\n",
    "# Create agency code column.\n",
    "df_file_preval['agency_code'] = df_file_preval['file_name_preval'].str.extract('_(.*?)_', expand=True)\n",
    "df_file_errors['agency_code'] = df_file_errors['file_name_error'].str.extract('_(.*?)_', expand=True)\n",
    "df_file_certs['agency_code'] = df_file_certs['file_name'].str.extract('_(.*?)_', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Outlook settings to retrieve messages from inbox.\n",
    "outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "inbox = outlook.GetDefaultFolder(6) # For main inbox\n",
    "# Restrict emails only from those that were received after the latest file was created.\n",
    "messages = inbox.Items.Restrict(\"[CreationTime] >='\" + date_file_str + \"'\")\n",
    "\n",
    "# Set initial lists and dataframes.\n",
    "submission = []\n",
    "df_preval = pd.DataFrame()\n",
    "df_prefain = pd.DataFrame()\n",
    "df_error = pd.DataFrame()\n",
    "df_errfain = pd.DataFrame()\n",
    "df_cert = pd.DataFrame()\n",
    "df_certfain = pd.DataFrame()\n",
    "\n",
    "# Create function to set agency based on file name.\n",
    "def set_agency(row):\n",
    "    if 'AM00' in str(row['file_name']):\n",
    "        return 'Agricultural Marketing Service'\n",
    "    elif 'AO00' in str(row['file_name']):\n",
    "        return 'Office of Advocacy and Outreach'\n",
    "    elif 'AP00' in str(row['file_name']):\n",
    "        return 'Animal and Plant Health Inspection Service'\n",
    "    elif 'AP02' in str(row['file_name']):\n",
    "        return 'Federal Shared Service Provider'\n",
    "    elif 'AR00' in str(row['file_name']) or 'AROO' in str(row['file_name']):\n",
    "        return 'Agricultural Research Service'\n",
    "    elif 'EC00' in str(row['file_name']):\n",
    "        return 'Office of the Chief Economist'\n",
    "    elif 'ER00' in str(row['file_name']):\n",
    "        return 'Economic Research Service'\n",
    "    elif 'FA00' in str(row['file_name']):\n",
    "        return 'Farm Service Agency'\n",
    "    elif 'FI00' in str(row['file_name']):\n",
    "        return 'Food Safety and Inspection Service'\n",
    "    elif 'FN00' in str(row['file_name']):\n",
    "        return'Food and Nutrition Service'\n",
    "    elif 'FS00' in str(row['file_name']):\n",
    "        return 'Forest Service'\n",
    "    elif 'FX00' in str(row['file_name']):\n",
    "        return 'Foreign Agricultural Service'\n",
    "    elif 'NA00' in str(row['file_name']):\n",
    "        return 'National Agricultural Statistics Service'\n",
    "    elif 'NI00' in str(row['file_name']):\n",
    "        return 'National Institute of Food and Agriculture'\n",
    "    elif 'NR00' in str(row['file_name']):\n",
    "        return 'Natural Resources Conservation Service '\n",
    "    elif 'RD00' in str(row['file_name']):\n",
    "        return 'Rural Development'\n",
    "    elif 'RM00' in str(row['file_name']):\n",
    "        return 'Risk Management Agency'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Function to create agency code and agency columns. \n",
    "def agency_col(df):\n",
    "    # Extract agency code from file name.\n",
    "    df['agency_code'] = df['file_name'].str.extract('_(.*?)_', expand=True)\n",
    "    # Apply set_agency function.\n",
    "    df['agency'] = df.apply(set_agency, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Loop Through and Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each message and filter accordingly.\n",
    "# Two sets of dataframes will be created for each category - one summarizes the metrics and other consists of the actual records.\n",
    "for m in messages:\n",
    "    #Extract date.\n",
    "    date_str = m.CreationTime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    date = dateutil.parser.parse(date_str)\n",
    "    \n",
    "    # Retrieve file submission messages.\n",
    "    if m.Subject.upper() == 'DATA ACT FILE SUBMISSION' and m.SenderName == 'OCFO - FMMI BI TEAM' or m.Subject.upper() == 'DATA ACT FILE SUBMISSION' and m.SenderName == 'FMMIBITEAM@cfo.usda.gov':\n",
    "        # Set file name and date received and agency.\n",
    "        date_submission = date\n",
    "        submission_file_name = re.search(r'file (.*?) has', m.Body).group(1)\n",
    "        # Append all records to submission list.\n",
    "        submission.append({'file_submission_notification_date': date_submission,'file_name': submission_file_name})\n",
    "        # Create dataframe.\n",
    "        df_submission = pd.DataFrame(submission)\n",
    "   \n",
    "    # Retrieve pre-validation error messages.\n",
    "    if m.Subject.upper() == 'DATA ACT D2 FILE SUBMISSION - PRE-VALIDATION ERROR' and  m.SenderName == 'BEREMOTE':\n",
    "        # Set date received.\n",
    "        date_preval = date\n",
    "        # Set filename and filepath and save to current directory.\n",
    "        attachment = m.Attachments.Item(1)\n",
    "        preval_attachment = attachment.FileName\n",
    "        attachment.SaveAsFile(os.getcwd() + '\\\\' + preval_attachment)\n",
    "        preval_file_name = preval_attachment[:-10]\n",
    "        \n",
    "        # Open text file with utf8 to prevent encoding errors. \n",
    "        with open (preval_attachment, 'rt', encoding='utf8') as txt_file:\n",
    "            preval_content = txt_file.read()\n",
    "            # Count instances of 'Error on line' in the text file.\n",
    "            preval_count = len(re.findall(r'Error on line:', preval_content, re.IGNORECASE))\n",
    "            # Split the text at \"Error on line\" for FAIN extraction.\n",
    "            preval_text = preval_content.split(\"Error on line:\",preval_count)[1:preval_count+1]\n",
    "            \n",
    "            # Loop through each resulting list element from the preceding split to extract the FAIN and action date.\n",
    "            for string in preval_text:\n",
    "                try:\n",
    "                    # Extract data elements after splitting at commas.\n",
    "                    preval_actdate = string.split(\",\")[5].strip() # Action date\n",
    "                    preval_fain = string.split(\",\")[8].strip() # FAIN\n",
    "                    preval_mod = string.split(\",\")[9].strip() # Award modification\n",
    "                    preval_uri = string.split(\",\")[10].strip() # URI\n",
    "                    preval_cfda = string.split(\",\")[32].strip() # CFDA\n",
    "                except Exception:\n",
    "                    preval_actdate = ''\n",
    "                    preval_fain = ''\n",
    "                    preval_mod = ''\n",
    "                    preval_uri = ''\n",
    "                    preval_cfda = ''\n",
    "                \n",
    "                #Convert to dataframe and set index=[0] to prevent scalar value error.\n",
    "                prefain = pd.DataFrame({'file_name': preval_file_name, 'notification_date': date_preval, 'action_date': preval_actdate, 'fain': preval_fain, 'award_modification': preval_mod, 'uri': preval_uri, 'cfda_number': preval_cfda}, index=[0])\n",
    "                # Append all dataframes created by the for loop.\n",
    "                df_prefain = df_prefain.append(prefain)\n",
    "                \n",
    "        # Apply agency_col function on the dataframe to create agency column.\n",
    "        agency_col(df_prefain)\n",
    "        \n",
    "        # Create a separate dataframe for the pre-validation error count.    \n",
    "        # Convert to dataframe and set index=[0] to prevent scalar value error.\n",
    "        preval_report = pd.DataFrame({'file_name': preval_file_name, 'preval_error_count': preval_count, 'preval_notification_date': date_preval}, index=[0])\n",
    "        # Append all dataframes created by the for loop.\n",
    "        df_preval = df_preval.append(preval_report)\n",
    "        # Delete file from current directory.\n",
    "        os.remove(preval_attachment)\n",
    "\n",
    "    # Retrieve D2 error report messages. \n",
    "    if 'DATA ACT D2 ERROR REPORT' in m.Subject.upper() and m.SenderName == 'OCFO - FMMI BI TEAM':\n",
    "        # Set filename and filepath and save to current directory.\n",
    "        attachment = m.Attachments.Item(1)\n",
    "        error_attachment = attachment.FileName\n",
    "        attachment.SaveAsFile(os.getcwd() + '\\\\' + error_attachment)\n",
    "        \n",
    "        # Extract the reporting period date from the attachment filename and convert to date time format.\n",
    "        date_error_text = error_attachment[-24:-5]\n",
    "        # date_error_text = re.search(r'period (.*?)\\.', m.Body).group(1) # Extract date from email body.\n",
    "        date_error_replace = date_error_text.replace('-','')\n",
    "        date_error = datetime.strptime(date_error_replace, '%Y%m%d%H%M%S')\n",
    "        \n",
    "        # Read into dataframe. \n",
    "        error_file = pd.read_excel(error_attachment, sheet_name='D2_Error_Records')\n",
    "        # Remove whitespace from column names.\n",
    "        error_file.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "        # Iterate through different versions of the source file column name to determine the correct one.\n",
    "        for col in error_file.columns:\n",
    "            if col=='Source File Name' or col=='FLEX_SOURCE_FILE_NAME':\n",
    "                source_col = col\n",
    "        \n",
    "        # Get error count in the source file name column.\n",
    "        error_file_count = error_file.loc[:,source_col].value_counts()\n",
    "        # Extract the action date, FAIN and source file name columns.\n",
    "        error_fain = error_file.loc[:,['Action Date', 'FAIN', 'Award Modification Amendment Number', 'URI', 'Federal Action Obligation', 'CFDA Number', source_col]]\n",
    "        # Rename columns.\n",
    "        error_fain.rename(columns={'Action Date': 'action_date', 'FAIN': 'fain', 'Award Modification Amendment Number': 'award_modification', 'URI': 'uri', 'Federal Action Obligation': 'obligation', 'CFDA Number': 'cfda_number', source_col: 'file_name'}, inplace=True)\n",
    "        # Add an error date column.\n",
    "        error_fain['D2_error_reporting_period'] = date_error\n",
    "        # Append all dataframes.\n",
    "        df_errfain = df_errfain.append(error_fain)\n",
    "        # Apply agency_col function on the dataframe to create agency column.\n",
    "        agency_col(df_errfain)\n",
    "        \n",
    "        # Create a separate dataframe for the D2 error count.\n",
    "        # Convert index (i.e., filename) and value (i.e., count) to list.\n",
    "        error_file_names = error_file_count.index.tolist()\n",
    "        error_count = error_file_count.values.tolist()\n",
    "        # List comprehension to assign reporting period date to each record.\n",
    "        error_report_period = [date_error for f in error_file_names] \n",
    "        # Convert to dataframe.\n",
    "        error_report = pd.DataFrame({'file_name': error_file_names, 'D2_error_count': error_count,'D2_error_reporting_period': error_report_period})\n",
    "        # Append all dataframes created by the for loop.\n",
    "        df_error = df_error.append(error_report)\n",
    "        # Delete file from current directory.\n",
    "        os.remove(error_attachment)\n",
    "        \n",
    "    # Retrieve D2 certification messages. \n",
    "    if 'DATA ACT D2 CERTIFICATION REPORT' in m.Subject.upper() and m.SenderName == 'OCFO - FMMI BI TEAM':       \n",
    "        # Set filename and filepath and save to current directory. \n",
    "        attachment = m.Attachments.Item(1)\n",
    "        cert_attachment = attachment.FileName\n",
    "        attachment.SaveAsFile(os.getcwd() + '\\\\' + cert_attachment)\n",
    "        \n",
    "        # Extract the reporting period date from the attachment filename and convert to date time format.\n",
    "        date_cert_text = cert_attachment[-24:-5]\n",
    "        # date_cert_text = re.search(r'period (.*?)\\.', m.Body).group(1) # Extract date from email body.\n",
    "        date_cert_replace = date_cert_text.replace('-','')\n",
    "        date_cert = datetime.strptime(date_cert_replace, '%Y%m%d%H%M%S')\n",
    "        \n",
    "        # Read into dataframe. \n",
    "        cert_file = pd.read_excel(cert_attachment, sheet_name='DATA ACT D2 CERTIFICATION REPOR')\n",
    "        # Remove whitespace from column names.\n",
    "        cert_file.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "        # Iterate through different versions of the source file column name to determine the correct one.\n",
    "        for col in cert_file.columns:\n",
    "            if col=='Source File Name' or col=='FLEX_SOURCE_FILE_NAME':\n",
    "                source_col = col\n",
    "        \n",
    "        # Get cert count in the source file name column.\n",
    "        cert_file_count = cert_file.loc[:,source_col].value_counts()\n",
    "        # Extract the action date, FAIN and source file name columns.\n",
    "        cert_fain = cert_file.loc[:,['ActionDate', 'FAIN', 'AwardModificationAmendmentNumber', 'URI', 'CFDA_Number', 'FederalActionObligation', source_col]]\n",
    "        # Rename columns.\n",
    "        cert_fain.rename(columns={'ActionDate': 'action_date', 'FAIN': 'fain', 'AwardModificationAmendmentNumber': 'award_modification', 'URI': 'uri', 'CFDA_Number': 'cfda_number', 'FederalActionObligation': 'obligation', source_col: 'file_name'}, inplace=True)\n",
    "        # Add a cert date column.\n",
    "        cert_fain['D2_cert_reporting_period'] = date_cert\n",
    "        # Append all dataframes.\n",
    "        df_certfain = df_certfain.append(cert_fain)\n",
    "        # Apply agency_col function on the dataframe to create agency column.\n",
    "        agency_col(df_certfain)\n",
    "        \n",
    "        # Create a separate dataframe for the D2 cert count.\n",
    "        # Convert index (i.e., filename) and value (i.e., count) to list.\n",
    "        cert_file_names = cert_file_count.index.tolist()\n",
    "        cert_count = cert_file_count.values.tolist()\n",
    "        # List comprehension to assign reporting period date to each record.\n",
    "        cert_report_period = [date_cert for f in cert_file_names]\n",
    "        # Convert to dataframe.\n",
    "        cert_report = pd.DataFrame({'file_name': cert_file_names, 'D2_certification_count': cert_count,'D2_cert_reporting_period': cert_report_period})\n",
    "        # Append all dataframes created by the for loop.\n",
    "        df_cert = df_cert.append(cert_report)\n",
    "        # Delete attachment from current directory.\n",
    "        os.remove(cert_attachment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Dataframe Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Submission Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply agency_col function on df_submission to create agency column.\n",
    "agency_col(df_submission)\n",
    "# Drop agency code column.\n",
    "df_submission = df_submission.drop('agency_code', axis=1)\n",
    "\n",
    "# Create subsets of the data from the latest file (to match with current dataframes).\n",
    "df_file_summ_sub = df_file_summary[['file_name', 'file_submission_notification_date', 'agency']]\n",
    "df_file_summ_preval = df_file_summary[['file_name', 'preval_error_count', 'preval_notification_date']]\n",
    "df_file_summ_err = df_file_summary[['file_name', 'D2_error_count', 'D2_error_reporting_period']]\n",
    "df_file_summ_cert = df_file_summary[['file_name', 'D2_certification_count', 'D2_cert_reporting_period']]\n",
    "\n",
    "# Append the current dataframes to the corresponding subsets.\n",
    "df_summ_comb = pd.concat([df_submission, df_file_summ_sub])\n",
    "df_prefile_comb = pd.concat([df_preval, df_file_summ_preval])\n",
    "df_errfile_comb = pd.concat([df_error, df_file_summ_err])\n",
    "df_certfile_comb = pd.concat([df_cert, df_file_summ_cert])\n",
    "\n",
    "# Create a sort and drop function.\n",
    "# Sort dataframes by descending date then drop duplicates (based on filename) and keep first instance (i.e., most recent based on sort).\n",
    "def sort_drop(df,col1,col2):\n",
    "    df.sort_values(by=[col1], ascending=False, inplace=True)\n",
    "    df = df.drop_duplicates(subset=[col2], keep='first', inplace=True)\n",
    "    \n",
    "# Apply the sort_drop function on the appended dataframes.\n",
    "sort_drop(df_summ_comb, 'file_submission_notification_date', 'file_name')\n",
    "sort_drop(df_prefile_comb, 'preval_notification_date', 'file_name')\n",
    "sort_drop(df_errfile_comb, 'D2_error_reporting_period', 'file_name') \n",
    "sort_drop(df_certfile_comb, 'D2_cert_reporting_period', 'file_name')\n",
    "\n",
    "# Merge dataframes on file_name.\n",
    "df_comb1 = pd.merge(df_summ_comb, df_prefile_comb, how='outer', on='file_name').fillna('')\n",
    "df_comb2 = pd.merge(df_comb1, df_errfile_comb, how='outer', on='file_name').fillna('')\n",
    "df_final_summ_comb = pd.merge(df_comb2, df_certfile_comb, how='outer', on='file_name').fillna('')\n",
    "\n",
    "# Rearrange columns.\n",
    "df_final_summ_comb = df_final_summ_comb[['file_submission_notification_date', 'file_name', 'agency', 'preval_error_count', 'preval_notification_date', 'D2_error_count', 'D2_error_reporting_period', 'D2_certification_count', 'D2_cert_reporting_period']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Prevalidation, Errors, and Certification Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop and rename applicable columns to match for dataframe merging.\n",
    "# Drop columns from latest file.\n",
    "df_file_preval = df_file_preval.drop(['D2_cert_reporting_period', 'file_name_cert'], axis=1)\n",
    "df_file_errors = df_file_errors.drop(['D2_cert_reporting_period', 'file_name_cert'], axis=1)\n",
    "\n",
    "# Rename file_name columns in current dataframes.\n",
    "df_prefain.rename(columns={'file_name': 'file_name_preval'}, inplace=True)\n",
    "df_errfain.rename(columns={'file_name': 'file_name_error'}, inplace=True)\n",
    "\n",
    "# Append current dataframes to latest file data.\n",
    "df_preval_comb = pd.concat([df_prefain, df_file_preval])\n",
    "df_error_comb = pd.concat([df_errfain, df_file_errors])\n",
    "df_cert_comb = pd.concat([df_certfain, df_file_certs])\n",
    "\n",
    "# Convert award_modification column to float to make format consistent for further procesing.\n",
    "# Function to convert.\n",
    "def con_num(df):\n",
    "    df['award_modification'] = pd.to_numeric(df['award_modification'], errors='coerce')\n",
    "\n",
    "# Apply con_num function.\n",
    "con_num(df_preval_comb)\n",
    "con_num(df_error_comb)\n",
    "con_num(df_cert_comb)\n",
    "\n",
    "# Function to create unique column for matching.\n",
    "def key_col(df):\n",
    "    df['ag_fain_mod_uri_cfda'] = df['agency_code'].astype(str) + df['fain'].astype(str) + df['award_modification'].astype(str) + df['uri'].astype(str) + df['cfda_number'].astype(str).str[:6]\n",
    "\n",
    "# Apply the key_col function on the appended dataframes.\n",
    "key_col(df_preval_comb)\n",
    "key_col(df_error_comb)\n",
    "key_col(df_cert_comb)\n",
    "\n",
    "# Apply the sort_drop function to delete duplicates.\n",
    "sort_drop(df_error_comb, 'D2_error_reporting_period', 'ag_fain_mod_uri_cfda') \n",
    "sort_drop(df_cert_comb, 'D2_cert_reporting_period', 'ag_fain_mod_uri_cfda')\n",
    "\n",
    "# Find matching records between prevalidation-certified and error-certified dataframes.\n",
    "df_pre_cert = pd.merge(df_preval_comb, df_cert_comb[['ag_fain_mod_uri_cfda', 'D2_cert_reporting_period', 'file_name']], how='left', on='ag_fain_mod_uri_cfda')\n",
    "df_err_cert = pd.merge(df_error_comb, df_cert_comb[['ag_fain_mod_uri_cfda', 'D2_cert_reporting_period', 'file_name']], how='left', on='ag_fain_mod_uri_cfda')\n",
    "\n",
    "# Rename and rearrange columns.\n",
    "df_pre_cert.rename(columns={'file_name': 'file_name_cert'}, inplace=True)\n",
    "df_err_cert.rename(columns={'file_name': 'file_name_cert'}, inplace=True)\n",
    "df_pre_cert = df_pre_cert[['file_name_preval', 'notification_date', 'agency', 'fain', 'uri', 'action_date', 'award_modification', 'cfda_number', 'file_name_cert', 'D2_cert_reporting_period']]\n",
    "df_err_cert = df_err_cert[['file_name_error', 'D2_error_reporting_period', 'agency', 'fain', 'uri', 'action_date', 'obligation', 'award_modification', 'cfda_number', 'file_name_cert', 'D2_cert_reporting_period']]\n",
    "df_cert_comb = df_cert_comb[['file_name', 'D2_cert_reporting_period', 'agency', 'fain', 'uri', 'action_date', 'obligation', 'award_modification', 'cfda_number']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create xlsx File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an xlsx file, one sheet for each dataframe.\n",
    "# Set timestamp and file destination path.\n",
    "timestr = time.strftime('%m_%d_%Y')\n",
    "# dest_path = r'\\\\wdcnetapp01\\\\CFOData$\\\\Data\\\\TARD\\\\DATA Act\\\\DATA Act D2 Error-Certs Files\\\\McStay report\\\\'\n",
    "\n",
    "# Set file name and save to path.\n",
    "file_name = 'D2_Files_Tracking_Report_'+ timestr + '.xlsx'\n",
    "writer = pd.ExcelWriter(dest_path + file_name, engine='xlsxwriter')\n",
    "df_final_summ_comb.to_excel(writer, 'Files_Summary', index=False)\n",
    "df_pre_cert.to_excel(writer, 'Prevals', index=False)\n",
    "df_err_cert.to_excel(writer, 'Errors', index=False)\n",
    "df_cert_comb.to_excel(writer, 'Certs', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Folder Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete files in the destination folder older than three months.\n",
    "# Loop through each file.\n",
    "today = date.today()\n",
    "for file in os.listdir(dest_path):\n",
    "    # Set file path.\n",
    "    file_path = os.path.join(dest_path, file)\n",
    "    # Extract the date from the file's name.\n",
    "    date_file_text = re.search(r'Report_(.*?).csv', file) or re.search(r'Report_(.*?).xlsx', file)\n",
    "    \n",
    "    # Use conditonal to prevent errors from non-matching files. \n",
    "    if date_file_text != None:\n",
    "        # Extract the date string from the match object.\n",
    "        date_file = date_file_text.group(1)\n",
    "        # Convert string to date time.\n",
    "        date_file = datetime.strptime(date_file, '%m_%d_%Y')\n",
    "        # Get difference between today and file's date.\n",
    "        date_diff = relativedelta.relativedelta(today, date_file)\n",
    "        months = date_diff.months\n",
    "        days = date_diff.days\n",
    "        \n",
    "        # Conditional to delete files older than three months.\n",
    "        if months >= 3 and days > 0:\n",
    "            os.unlink(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Bar Chart\n",
    "Agency totals for errors and certified records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create agency acronym column.\n",
    "def agency_acronym(row):\n",
    "    if row['agency'] == 'Agricultural Marketing Service':\n",
    "        return 'AMS'\n",
    "    elif row['agency'] == 'Office of Advocacy and Outreach':\n",
    "        return 'OAO'\n",
    "    elif row['agency'] == 'Animal and Plant Health Inspection Service':\n",
    "        return 'APHIS'\n",
    "    elif row['agency'] == 'Federal Shared Service Provider':\n",
    "        return 'FSSP'\n",
    "    elif row['agency'] == 'Agricultural Research Service':\n",
    "        return 'ARS'\n",
    "    elif row['agency'] == 'Office of the Chief Economist':\n",
    "        return 'OCE'\n",
    "    elif row['agency'] == 'Economic Research Service':\n",
    "        return 'ERS'\n",
    "    elif row['agency'] == 'Farm Service Agency':\n",
    "        return 'FSA'\n",
    "    elif row['agency'] == 'Food Safety and Inspection Service':\n",
    "        return 'FSIS'\n",
    "    elif row['agency'] == 'Food and Nutrition Service':\n",
    "        return 'FNS'\n",
    "    elif row['agency'] == 'Forest Service':\n",
    "        return 'FS'\n",
    "    elif row['agency'] == 'Foreign Agricultural Service':\n",
    "        return 'FAS'\n",
    "    elif row['agency'] == 'National Agricultural Statistics Service':\n",
    "        return 'NASS'\n",
    "    elif row['agency'] == 'National Institute of Food and Agriculture':\n",
    "        return 'NIFA'\n",
    "    elif row['agency'] == 'Natural Resources Conservation Service ':\n",
    "        return 'NRCS'\n",
    "    elif row['agency'] == 'Rural Development':\n",
    "        return 'RD'\n",
    "    elif row['agency'] == 'Risk Management Agency':\n",
    "        return 'RMA'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def agency_acr_col(df):\n",
    "    df['ag_acr'] = df.apply(agency_acronym, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby agency.\n",
    "df_agency_err = df_err_cert.groupby('agency').agg({'file_name_error': 'count', 'file_name_cert': 'count'}).reset_index()\n",
    "df_agency_err['outstanding_errors'] = df_agency_err['file_name_error'] - df_agency_err['file_name_cert']\n",
    "df_agency_cert = df_cert_comb.groupby('agency').agg({'file_name': 'count'}).reset_index()\n",
    "\n",
    "# Apply agency_acronym function.\n",
    "agency_acr_col(df_agency_err)\n",
    "agency_acr_col(df_agency_cert)\n",
    "\n",
    "# Create error bar chart.\n",
    "trace_errb1 = go.Bar(\n",
    "    x=df_agency_err['ag_acr'],  \n",
    "    y=df_agency_err['outstanding_errors'],\n",
    "    name = 'Outstanding Errors', \n",
    "    marker=dict(color='red')\n",
    ")\n",
    "trace_errb2 = go.Bar(\n",
    "    x=df_agency_err['ag_acr'],\n",
    "    y=df_agency_err['file_name_cert'],\n",
    "    name='Resolved Errors', \n",
    "    marker=dict(color='green')\n",
    ")\n",
    "data_errb = [trace_errb1, trace_errb2]\n",
    "layout_errb = go.Layout(\n",
    "    title='<b>Total Errors</b>',\n",
    "    font=dict(family='century gothic', size=13),\n",
    "    barmode='stack'\n",
    ")\n",
    "fig_errb = go.Figure(data=data_errb, layout=layout_errb)\n",
    "# pyo.plot(fig_errb, filename='D2_Outstanding_Errors.html') # Create an html file.\n",
    "\n",
    "# Create certified records bar chart.\n",
    "data_certb = [go.Bar(\n",
    "    x=df_agency_cert['ag_acr'],  \n",
    "    y=df_agency_cert['file_name']\n",
    ")]\n",
    "layout_certb = go.Layout(\n",
    "    title='<b>Total Certified Records</b>',\n",
    "    font=dict(family='century gothic', size=13)\n",
    ")\n",
    "fig_certb = go.Figure(data=data_certb, layout=layout_certb)\n",
    "# pyo.plot(fig_certb, filename='D2_Certified_Records.html') # Create an html file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Line Chart\n",
    "Monthly plots of errors and certified records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a month-year column.\n",
    "# Function to create and convert to date format the month-year column.\n",
    "def date_convert(df,col):\n",
    "    df['notification_month_year'] = df[col].dt.strftime('%B %Y')\n",
    "    df['notification_month_year'] = pd.to_datetime(df['notification_month_year'],format='%B %Y')\n",
    "\n",
    "# Apply date_convert function.\n",
    "date_convert(df_err_cert,'D2_error_reporting_period')\n",
    "date_convert(df_cert_comb,'D2_cert_reporting_period')\n",
    "\n",
    "# Groupby month-year, one for total and another broken down by agency \n",
    "err_date = df_err_cert.groupby(['notification_month_year','agency'])[['file_name_error']].count().reset_index()\n",
    "err_date_total = df_err_cert.groupby(['notification_month_year'])[['file_name_error']].count().reset_index()\n",
    "cert_date = df_cert_comb.groupby(['notification_month_year','agency'])[['file_name']].count().reset_index()\n",
    "cert_date_total = df_cert_comb.groupby(['notification_month_year'])[['file_name']].count().reset_index()\n",
    "\n",
    "# Apply agency_acronym function.\n",
    "agency_acr_col(err_date)\n",
    "agency_acr_col(cert_date)\n",
    "\n",
    "# Agency breakdown line chart for errors.\n",
    "data_errl=[]\n",
    "for agency in err_date['ag_acr'].unique():\n",
    "    trace_errl = go.Scatter(\n",
    "    x=err_date['notification_month_year'][err_date['ag_acr']==agency],\n",
    "    y=err_date['file_name_error'][err_date['ag_acr']==agency],\n",
    "    name=agency\n",
    "    )\n",
    "    data_errl.append(trace_errl)\n",
    "layout_errl = go.Layout(\n",
    "    title='<b>Monthly Errors</b>',\n",
    "    font=dict(family='century gothic', size=13)\n",
    "    )\n",
    "fig_errl = go.Figure(data=data_errl, layout=layout_errl)\n",
    "# pyo.plot(fig_errl, filename='D2_Monthly_Errors.html') # Create an html file.\n",
    "\n",
    "# Agency breakdown line chart for certified records.\n",
    "data_certl=[]\n",
    "for agency in cert_date['ag_acr'].unique():\n",
    "    trace_certl = go.Scatter(\n",
    "    x=cert_date['notification_month_year'][cert_date['ag_acr']==agency],\n",
    "    y=cert_date['file_name'][cert_date['ag_acr']==agency],\n",
    "    name=agency\n",
    ")\n",
    "    data_certl.append(trace_certl)\n",
    "layout_certl = go.Layout(\n",
    "    title='<b>Monthly Certified Records</b>',\n",
    "    font=dict(family='century gothic', size=13)\n",
    "    )\n",
    "fig_certl = go.Figure(data=data_certl, layout=layout_certl)\n",
    "# pyo.plot(fig_certl, filename='D2_Monthly_Certified.html') # Create an html file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Subplots\n",
    "Combine the separate plots and show on one page using Plotly's subplot feature (i.e., in lieu of a dashboard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y1 ]\n",
      "[ (2,1) x1,y2 ]  [ (2,2) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file://C:\\\\Users\\\\JMcStay\\\\Desktop\\\\Python Projects\\\\D2_Plots.html'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define subplot features.\n",
    "fig_subp = tools.make_subplots(rows=2, cols=2,\n",
    "                           shared_xaxes=True,\n",
    "                           shared_yaxes=True,\n",
    "                           subplot_titles=('<b>Total Certified Records</b>', '<b>Monthly Certified Records</b>',\n",
    "                                           '<b>Total Errors</b>', '<b>Monthly Errors</b>'))\n",
    "\n",
    "# Set plot colors.\n",
    "colors = {'AMS':'blue',\n",
    "          'OAO':'olivedrab',\n",
    "          'APHIS':'brown',\n",
    "          'FSSP':'burlywood',\n",
    "          'ARS':'chartreuse',\n",
    "          'OCE':'coral',\n",
    "          'ERS':'darkcyan',\n",
    "          'FSA':'orange',\n",
    "          'FSIS':'hotpink',\n",
    "          'FNS':'indianred',\n",
    "          'FS':'red',\n",
    "          'FAS':'darkviolet',\n",
    "          'NASS':'tomato',\n",
    "          'NIFA':'gold',\n",
    "          'NRCS':'seagreen',\n",
    "          'RD':'purple',\n",
    "          'RMA':'yellow',\n",
    "          }\n",
    "\n",
    "# Append certified records bar chart.\n",
    "fig_subp.append_trace({'x':df_agency_cert['ag_acr'],\n",
    "                       'y':df_agency_cert['file_name'],\n",
    "                       'name':'Certified Records',\n",
    "                       'marker':dict(color='darkblue'),\n",
    "                       'type':'bar'}, row=1, col=1)\n",
    "\n",
    "# Append error bar charts.    \n",
    "fig_subp.append_trace({'x':df_agency_err['ag_acr'],\n",
    "                       'y':df_agency_err['outstanding_errors'],\n",
    "                       'name':'Outstanding Errors',\n",
    "                       'marker':dict(color='red'),\n",
    "                       'type':'bar',\n",
    "                       'offset': -0.4}, row=2, col=1)\n",
    "\n",
    "fig_subp.append_trace({'x':df_agency_err['ag_acr'],\n",
    "                       'y':df_agency_err['file_name_cert'],\n",
    "                       'name':'Resolved Errors',\n",
    "                       'marker':dict(color='green'),\n",
    "                       'type':'bar',\n",
    "                       'offset': -0.4}, row=2, col=1)\n",
    "\n",
    "# Append certified records line chart.\n",
    "data_certl_sp=[]\n",
    "for agency in cert_date['ag_acr'].sort_values().unique():\n",
    "    fig_subp.append_trace({'x':cert_date['notification_month_year'][cert_date['ag_acr']==agency],\n",
    "                           'y':cert_date['file_name'][cert_date['ag_acr']==agency],\n",
    "                           'name':agency,\n",
    "                           'legendgroup':agency,\n",
    "                           'marker':{'color': colors[agency]},\n",
    "                           'type':'scatter'}, row=1, col=2)\n",
    "    data_certl_sp.append(agency)\n",
    "\n",
    "# Append error line charts.\n",
    "data_errl_sp=[]\n",
    "for agency in err_date['ag_acr'].unique():\n",
    "    fig_subp.append_trace({'x':err_date['notification_month_year'][err_date['ag_acr']==agency],\n",
    "                           'y':err_date['file_name_error'][err_date['ag_acr']==agency],\n",
    "                           'name':agency,\n",
    "                           'legendgroup':agency,\n",
    "                           'showlegend' : False if agency in data_certl_sp else True,\n",
    "                           'marker':{'color': colors[agency]},\n",
    "                           'type':'scatter'}, row=2, col=2)              \n",
    "    data_errl_sp.append(agency)\n",
    "\n",
    "# Set plot name.\n",
    "fig_subp['layout'].update(title='<b>D2 Files Summary</b> '+'<b>'+timestr+'</b>')\n",
    "# Set subplot titles' font.\n",
    "for i in fig_subp['layout']['annotations']:\n",
    "    i['font'] = dict(family='century gothic', size=15)\n",
    "# Create html file.\n",
    "pyo.plot(fig_subp, filename='D2_Plots.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Dash\n",
    "Create a basic dashboard in Dash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Sep/2018 09:15:30] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Sep/2018 09:15:32] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Sep/2018 09:15:32] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Sep/2018 09:15:32] \"GET /favicon.ico HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Use the Plotly plots from 8a and 8b and append onto dashboard. \n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "    html.H1(\n",
    "        'D2 Files Summary', \n",
    "        style={\n",
    "            'textAlign': 'center',\n",
    "            'font-family': 'century gothic'\n",
    "        }\n",
    "    ),\n",
    "    \n",
    "    html.Div(\n",
    "        children='As of '+ timestr,\n",
    "        style={\n",
    "            'textAlign': 'center',\n",
    "            'font-family': 'century gothic',\n",
    "            'fontSize':20\n",
    "        }\n",
    "    ),\n",
    "        \n",
    "    html.Div([\n",
    "        dcc.Graph(\n",
    "            id='cert_bars', \n",
    "            figure=fig_certb\n",
    "        ),\n",
    "        dcc.Graph(\n",
    "            id='error_bars', \n",
    "            figure=fig_errb)], \n",
    "        style={\n",
    "            'width': '50%', \n",
    "            'display': 'inline-block'\n",
    "        }\n",
    "    ),\n",
    "    \n",
    "    html.Div([\n",
    "        dcc.Graph(\n",
    "            id='cert_lines', \n",
    "            figure=fig_certl\n",
    "        ),\n",
    "        dcc.Graph(\n",
    "            id='error_lines',\n",
    "            figure=fig_errl)], \n",
    "        style={\n",
    "            'width': '50%', \n",
    "            'display': 'inline-block'\n",
    "        }\n",
    "    )\n",
    "])\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 10. Note\n",
    "To automate code execution, convert to a py file and run through Windows Task Scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
