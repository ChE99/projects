{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from Emails - Part 1 of 2\n",
    "Extract information from Outlook emails using Win32 (and other applicable methods such as regex). The code for this project consists of two parts. The first part creates the initial file after going through all the emails in inbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import win32com.client\n",
    "import re\n",
    "import time\n",
    "import dateutil.parser\n",
    "from dateutil import parser\n",
    "from dateutil import relativedelta\n",
    "from datetime import datetime\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Outlook settings to retrieve messages from inbox.\n",
    "outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "inbox = outlook.GetDefaultFolder(6) # For main inbox. To search within a subfolder add .Folders.Item(\"subfolder name\").\n",
    "messages = inbox.Items\n",
    "\n",
    "# Set initial lists and dataframes.\n",
    "submission = []\n",
    "df_preval = pd.DataFrame()\n",
    "df_prefain = pd.DataFrame()\n",
    "df_error = pd.DataFrame()\n",
    "df_errfain = pd.DataFrame()\n",
    "df_cert = pd.DataFrame()\n",
    "df_certfain = pd.DataFrame()\n",
    "\n",
    "# Create a function to set agency based on file name.\n",
    "def set_agency(row):\n",
    "    if 'AM00' in str(row['file_name']):\n",
    "        return 'Agricultural Marketing Service'\n",
    "    elif 'AO00' in str(row['file_name']):\n",
    "        return 'Office of Advocacy and Outreach'\n",
    "    elif 'AP00' in str(row['file_name']):\n",
    "        return 'Animal and Plant Health Inspection Service'\n",
    "    elif 'AP02' in str(row['file_name']):\n",
    "        return 'Federal Shared Service Provider'\n",
    "    elif 'AR00' in str(row['file_name']) or 'AROO' in str(row['file_name']):\n",
    "        return 'Agricultural Research Service'\n",
    "    elif 'EC00' in str(row['file_name']):\n",
    "        return 'Office of the Chief Economist'\n",
    "    elif 'ER00' in str(row['file_name']):\n",
    "        return 'Economic Research Service'\n",
    "    elif 'FA00' in str(row['file_name']):\n",
    "        return 'Farm Service Agency'\n",
    "    elif 'FI00' in str(row['file_name']):\n",
    "        return 'Food Safety and Inspection Service'\n",
    "    elif 'FN00' in str(row['file_name']):\n",
    "        return'Food and Nutrition Service'\n",
    "    elif 'FS00' in str(row['file_name']):\n",
    "        return 'Forest Service'\n",
    "    elif 'FX00' in str(row['file_name']):\n",
    "        return 'Foreign Agricultural Service'\n",
    "    elif 'NA00' in str(row['file_name']):\n",
    "        return 'National Agricultural Statistics Service'\n",
    "    elif 'NI00' in str(row['file_name']):\n",
    "        return 'National Institute of Food and Agriculture'\n",
    "    elif 'NR00' in str(row['file_name']):\n",
    "        return 'Natural Resources Conservation Service '\n",
    "    elif 'RD00' in str(row['file_name']):\n",
    "        return 'Rural Development'\n",
    "    elif 'RM00' in str(row['file_name']):\n",
    "        return 'Risk Management Agency'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Function to create agency code and agency columns. \n",
    "def agency_col(df):\n",
    "    # Extract agency code from file name.\n",
    "    df['agency_code'] = df['file_name'].str.extract('_(.*?)_', expand=True)\n",
    "    # Apply set_agency function.\n",
    "    df['agency'] = df.apply(set_agency, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loop Through and Set\n",
    "Loop through and identify D2-related messages and set parameters and values for:\n",
    "\n",
    "-  File submissions\n",
    "-  Pre-validation errors\n",
    "-  D2 error reports\n",
    "-  D2 certifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop through each message and filter accordingly.\n",
    "for m in messages:\n",
    "    #Extract date.\n",
    "    date_str = m.CreationTime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    date = dateutil.parser.parse(date_str)\n",
    "    \n",
    "    # Retrieve file submission messages.\n",
    "    if m.Subject.upper() == 'DATA ACT FILE SUBMISSION' and m.SenderName == 'OCFO - FMMI BI TEAM' or m.Subject.upper() == 'DATA ACT FILE SUBMISSION' and m.SenderName == 'FMMIBITEAM@cfo.usda.gov':\n",
    "        # Set file name and date received and agency.\n",
    "        date_submission = date\n",
    "        submission_file_name = re.search(r'file (.*?) has', m.Body).group(1)\n",
    "        # Append all records to submission list.\n",
    "        submission.append({'file_submission_notification_date': date_submission,'file_name': submission_file_name})\n",
    "        # Create dataframe.\n",
    "        df_submission = pd.DataFrame(submission)\n",
    "   \n",
    "    # Retrieve pre-validation error messages.\n",
    "    if m.Subject.upper() == 'DATA ACT D2 FILE SUBMISSION - PRE-VALIDATION ERROR' and  m.SenderName == 'BEREMOTE' or m.Subject.upper() == 'FW: DATA ACT D2 FILE SUBMISSION - PRE-VALIDATION ERROR' and m.SenderName == 'Smith, John - OCFO, Washington, DC':\n",
    "        # Set date based on email receipt, i.e., directly or forwarded.\n",
    "        if m.Subject.upper() == 'DATA ACT D2 FILE SUBMISSION - PRE-VALIDATION ERROR' and m.SenderName == 'BEREMOTE':\n",
    "            date_preval = date\n",
    "        else:\n",
    "            # Extract the sent date from the body of the forwarded email.\n",
    "            date_preval_text = re.search(r'day, (.*?)\\n', m.Body).group(1)\n",
    "            # Split at \"(\" for date formats containing (UTC)...\n",
    "            date_preval_text = date_preval_text.split(' (')[0]\n",
    "            # Convert date string to date-time.\n",
    "            date_preval = parser.parse(date_preval_text)\n",
    "        \n",
    "        # Set filename and filepath and save to current directory.\n",
    "        attachment = m.Attachments.Item(1)\n",
    "        preval_attachment = attachment.FileName\n",
    "        attachment.SaveAsFile(os.getcwd() + '\\\\' + preval_attachment)\n",
    "        preval_file_name = preval_attachment[:-10]\n",
    "        \n",
    "        # Open text file with utf8 to prevent encoding errors. \n",
    "        with open (preval_attachment, 'rt', encoding='utf8') as txt_file:\n",
    "            preval_content = txt_file.read()\n",
    "            # Count instances of 'Error on line' in the text file.\n",
    "            preval_count = len(re.findall(r'Error on line:', preval_content, re.IGNORECASE))\n",
    "            # Split the text at \"Error on line\" for FAIN extraction.\n",
    "            preval_text = preval_content.split(\"Error on line:\",preval_count)[1:preval_count+1]\n",
    "            \n",
    "            # Loop through each resulting list element from the preceding split to extract the FAIN and action date.\n",
    "            for string in preval_text:\n",
    "                try:\n",
    "                    # Extract data elements after splitting at commas.\n",
    "                    preval_actdate = string.split(\",\")[5].strip() # Action date\n",
    "                    preval_fain = string.split(\",\")[8].strip() # FAIN\n",
    "                    preval_mod = string.split(\",\")[9].strip() # Award modification\n",
    "                    preval_uri = string.split(\",\")[10].strip() # URI\n",
    "                    preval_cfda = string.split(\",\")[32].strip() # CFDA\n",
    "                except Exception:\n",
    "                    preval_actdate = ''\n",
    "                    preval_fain = ''\n",
    "                    preval_mod = ''\n",
    "                    preval_uri = ''\n",
    "                    preval_cfda = ''\n",
    "                \n",
    "                #Convert to dataframe and set index=[0] to prevent scalar value error.\n",
    "                prefain = pd.DataFrame({'file_name': preval_file_name, 'notification_date': date_preval, 'action_date': preval_actdate, 'fain': preval_fain, 'award_modification': preval_mod, 'uri': preval_uri, 'cfda_number': preval_cfda}, index=[0])\n",
    "                # Append all dataframes created by the for loop.\n",
    "                df_prefain = df_prefain.append(prefain)\n",
    "                \n",
    "        # Apply agency_col function on the dataframe to create agency column.\n",
    "        agency_col(df_prefain)\n",
    "        \n",
    "        # Create a separate dataframe for the pre-validation error count.    \n",
    "        # Convert to dataframe and set index=[0] to prevent scalar value error.\n",
    "        preval_report = pd.DataFrame({'file_name': preval_file_name, 'preval_error_count': preval_count, 'preval_notification_date': date_preval}, index=[0])\n",
    "        # Append all dataframes created by the for loop.\n",
    "        df_preval = df_preval.append(preval_report)\n",
    "        # Delete file from current directory.\n",
    "        os.remove(preval_attachment)\n",
    "\n",
    "    # Retrieve D2 error report messages. Set additional condition 'and len(re.findall...)==1' to filter out replies to forwarded messages.\n",
    "    if 'DATA ACT D2 ERROR REPORT' in m.Subject.upper() and m.SenderName == 'OCFO - FMMI BI TEAM' or 'FW: DATA ACT D2 ERROR REPORT' in m.Subject.upper() and m.SenderName == 'Smith, John - OCFO, Washington, DC' and len(re.findall(r'From:', m.Body)) == 1:\n",
    "        # Set filename and filepath and save to current directory.\n",
    "        attachment = m.Attachments.Item(1)\n",
    "        error_attachment = attachment.FileName\n",
    "        attachment.SaveAsFile(os.getcwd() + '\\\\' + error_attachment)\n",
    "        \n",
    "        # Extract the reporting period date from the attachment filename and convert to date time format.\n",
    "        date_error_text = error_attachment[-24:-5]\n",
    "        # date_error_text = re.search(r'period (.*?)\\.', m.Body).group(1) # Extract date from email body.\n",
    "        date_error_replace = date_error_text.replace('-','')\n",
    "        date_error = datetime.strptime(date_error_replace, '%Y%m%d%H%M%S')\n",
    "        \n",
    "        # Read into dataframe. \n",
    "        error_file = pd.read_excel(error_attachment, sheet_name='D2_Error_Records')\n",
    "        # Remove whitespace from column names.\n",
    "        error_file.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "        # Iterate through different versions of the source file column name to determine the correct one.\n",
    "        for col in error_file.columns:\n",
    "            if col=='Source File Name' or col=='FLEX_SOURCE_FILE_NAME':\n",
    "                source_col = col\n",
    "        \n",
    "        # Get error count in the source file name column.\n",
    "        error_file_count = error_file.loc[:,source_col].value_counts()\n",
    "        # Extract the action date, FAIN and source file name columns.\n",
    "        error_fain = error_file.loc[:,['Action Date', 'FAIN', 'Award Modification Amendment Number', 'URI', 'Federal Action Obligation', 'CFDA Number', source_col]]\n",
    "        # Rename columns.\n",
    "        error_fain.rename(columns={'Action Date': 'action_date', 'FAIN': 'fain', 'Award Modification Amendment Number': 'award_modification', 'URI': 'uri', 'Federal Action Obligation': 'obligation', 'CFDA Number': 'cfda_number', source_col: 'file_name'}, inplace=True)\n",
    "        # Add an error date column.\n",
    "        error_fain['D2_error_reporting_period'] = date_error\n",
    "        # Append all dataframes.\n",
    "        df_errfain = df_errfain.append(error_fain)\n",
    "        # Apply agency_col function on the dataframe to create agency column.\n",
    "        agency_col(df_errfain)\n",
    "        \n",
    "        # Create a separate dataframe for the D2 error count.\n",
    "        # Convert index (i.e., filename) and value (i.e., count) to list.\n",
    "        error_file_names = error_file_count.index.tolist()\n",
    "        error_count = error_file_count.values.tolist()\n",
    "        # List comprehension to assign reporting period date to each record.\n",
    "        error_report_period = [date_error for f in error_file_names] \n",
    "        # Convert to dataframe.\n",
    "        error_report = pd.DataFrame({'file_name': error_file_names, 'D2_error_count': error_count,'D2_error_reporting_period': error_report_period})\n",
    "        # Append all dataframes created by the for loop.\n",
    "        df_error = df_error.append(error_report)\n",
    "        # Delete file from current directory.\n",
    "        os.remove(error_attachment)\n",
    "        \n",
    "    # Retrieve D2 certification messages. Set additional condition 'and len(re.findall...)==1' to filter out replies to forwarded messages.\n",
    "    if 'DATA ACT D2 CERTIFICATION REPORT' in m.Subject.upper() and m.SenderName == 'OCFO - FMMI BI TEAM' or 'FW: DATA ACT D2 CERTIFICATION REPORT' in m.Subject.upper() and m.SenderName == 'Smith, John - OCFO, Washington, DC' and len(re.findall(r'From:', m.Body)) == 1:       \n",
    "        # Set filename and filepath and save to current directory. \n",
    "        attachment = m.Attachments.Item(1)\n",
    "        cert_attachment = attachment.FileName\n",
    "        attachment.SaveAsFile(os.getcwd() + '\\\\' + cert_attachment)\n",
    "        \n",
    "        # Extract the reporting period date from the attachment filename and convert to date time format.\n",
    "        date_cert_text = cert_attachment[-24:-5]\n",
    "        # date_cert_text = re.search(r'period (.*?)\\.', m.Body).group(1) # Extract date from email body.\n",
    "        date_cert_replace = date_cert_text.replace('-','')\n",
    "        date_cert = datetime.strptime(date_cert_replace, '%Y%m%d%H%M%S')\n",
    "        \n",
    "        # Read into dataframe. \n",
    "        cert_file = pd.read_excel(cert_attachment, sheet_name='DATA ACT D2 CERTIFICATION REPOR')\n",
    "        # Remove whitespace from column names.\n",
    "        cert_file.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "        # Iterate through different versions of the source file column name to determine the correct one.\n",
    "        for col in cert_file.columns:\n",
    "            if col=='Source File Name' or col=='FLEX_SOURCE_FILE_NAME':\n",
    "                source_col = col\n",
    "        \n",
    "        # Get cert count in the source file name column.\n",
    "        cert_file_count = cert_file.loc[:,source_col].value_counts()\n",
    "        # Extract the action date, FAIN and source file name columns.\n",
    "        cert_fain = cert_file.loc[:,['ActionDate', 'FAIN', 'AwardModificationAmendmentNumber', 'URI', 'CFDA_Number', 'FederalActionObligation', source_col]]\n",
    "        # Rename columns.\n",
    "        cert_fain.rename(columns={'ActionDate': 'action_date', 'FAIN': 'fain', 'AwardModificationAmendmentNumber': 'award_modification', 'URI': 'uri', 'CFDA_Number': 'cfda_number', 'FederalActionObligation': 'obligation', source_col: 'file_name'}, inplace=True)\n",
    "        # Add a cert date column.\n",
    "        cert_fain['D2_cert_reporting_period'] = date_cert\n",
    "        # Append all dataframes.\n",
    "        df_certfain = df_certfain.append(cert_fain)\n",
    "        # Apply agency_col function on the dataframe to create agency column.\n",
    "        agency_col(df_certfain)\n",
    "        \n",
    "        # Create a separate dataframe for the D2 cert count.\n",
    "        # Convert index (i.e., filename) and value (i.e., count) to list.\n",
    "        cert_file_names = cert_file_count.index.tolist()\n",
    "        cert_count = cert_file_count.values.tolist()\n",
    "        # List comprehension to assign reporting period date to each record.\n",
    "        cert_report_period = [date_cert for f in cert_file_names]\n",
    "        # Convert to dataframe.\n",
    "        cert_report = pd.DataFrame({'file_name': cert_file_names, 'D2_certification_count': cert_count,'D2_cert_reporting_period': cert_report_period})\n",
    "        # Append all dataframes created by the for loop.\n",
    "        df_cert = df_cert.append(cert_report)\n",
    "        # Delete attachment from current directory.\n",
    "        os.remove(cert_attachment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dataframe Processing\n",
    "The final file will consist of four sheets created from the following dataframes: (1) a submission summary, (2) the prevalidation errors, and (3) D2 error records with a crosswalk to (4) the certified records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Submission Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort dataframes by descending date then drop duplicates (based on filename) and keep first instance (i.e., most recent based on sort).\n",
    "# Create a sort and drop function.\n",
    "def sort_drop(df,col1,col2):\n",
    "    df.sort_values(by=[col1], ascending=False, inplace=True)\n",
    "    df = df.drop_duplicates(subset=[col2], keep='first', inplace=True)\n",
    "    \n",
    "# Apply the sort_drop function on the dataframes.\n",
    "sort_drop(df_submission, 'file_submission_notification_date', 'file_name')  \n",
    "sort_drop(df_preval, 'preval_notification_date', 'file_name')\n",
    "sort_drop(df_error, 'D2_error_reporting_period', 'file_name') \n",
    "sort_drop(df_cert, 'D2_cert_reporting_period', 'file_name')\n",
    "\n",
    "# Merge dataframes on file_name.\n",
    "df_comb1 = pd.merge(df_submission, df_preval, how='outer', on='file_name').fillna('')\n",
    "df_comb2 = pd.merge(df_comb1, df_error, how='outer', on='file_name').fillna('')\n",
    "df_summ_comb = pd.merge(df_comb2, df_cert, how='outer', on='file_name').fillna('')\n",
    "\n",
    "# Apply the agency_col function on the dataframe to create an agency column.\n",
    "agency_col(df_summ_comb)\n",
    "# Rearrange columns.\n",
    "df_summ_comb = df_summ_comb[['file_submission_notification_date', 'file_name', 'agency', 'preval_error_count', 'preval_notification_date', 'D2_error_count', 'D2_error_reporting_period', 'D2_certification_count', 'D2_cert_reporting_period']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Prevalidation, Errors, and Certification Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert award_modification column to float to make format consistent for further procesing.\n",
    "# Function to convert.\n",
    "def con_num(df):\n",
    "    df['award_modification'] = pd.to_numeric(df['award_modification'], errors='coerce')\n",
    "\n",
    "# Apply con_num function.\n",
    "con_num(df_prefain)\n",
    "con_num(df_errfain)\n",
    "con_num(df_certfain)\n",
    "\n",
    "# Function to create a unique column for matching.\n",
    "def key_col(df):\n",
    "    df['ag_fain_mod_uri_cfda'] = df['agency_code'].astype(str) + df['fain'].astype(str) + df['award_modification'].astype(str) + df['uri'].astype(str) + df['cfda_number'].astype(str).str[:6]\n",
    "\n",
    "# Apply the key_col function on the prevalidation, errors, and certification dataframes for subsequent cross-walking. \n",
    "key_col(df_prefain)\n",
    "key_col(df_errfain)\n",
    "key_col(df_certfain)\n",
    "\n",
    "# Apply the sort_drop function on the dataframes to remove duplicates.\n",
    "sort_drop(df_errfain, 'D2_error_reporting_period', 'ag_fain_mod_uri_cfda') \n",
    "sort_drop(df_certfain, 'D2_cert_reporting_period', 'ag_fain_mod_uri_cfda')\n",
    "\n",
    "# Find matching records between preval-cert and error-cert dataframes.\n",
    "df_pre_cert = pd.merge(df_prefain, df_certfain[['ag_fain_mod_uri_cfda', 'D2_cert_reporting_period', 'file_name']], how='left', on='ag_fain_mod_uri_cfda')\n",
    "df_err_cert = pd.merge(df_errfain, df_certfain[['ag_fain_mod_uri_cfda', 'D2_cert_reporting_period', 'file_name']], how='left', on='ag_fain_mod_uri_cfda')\n",
    "\n",
    "# Rename and rearrange columns.\n",
    "df_pre_cert.rename(columns={'file_name_x': 'file_name_preval', 'file_name_y': 'file_name_cert'}, inplace=True)\n",
    "df_err_cert.rename(columns={'file_name_x': 'file_name_error', 'file_name_y': 'file_name_cert'}, inplace=True)\n",
    "df_pre_cert = df_pre_cert[['file_name_preval', 'notification_date', 'agency', 'fain', 'uri', 'action_date', 'award_modification', 'cfda_number', 'file_name_cert', 'D2_cert_reporting_period']]\n",
    "df_err_cert = df_err_cert[['file_name_error', 'D2_error_reporting_period', 'agency', 'fain', 'uri', 'action_date', 'obligation', 'award_modification', 'cfda_number', 'file_name_cert', 'D2_cert_reporting_period']]\n",
    "df_certfain = df_certfain[['file_name', 'D2_cert_reporting_period', 'agency', 'fain', 'uri', 'action_date', 'obligation', 'award_modification', 'cfda_number']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create xlsx File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an xlsx file, one sheet for each dataframe.\n",
    "# Set timestamp and file destination path.\n",
    "timestr = time.strftime('%m_%d_%Y')\n",
    "dest_path = os.getcwd() + '\\\\'\n",
    "\n",
    "# Set file name and save to path.\n",
    "file_name = 'D2_Files_Tracking_Report_'+ timestr + '.xlsx'\n",
    "writer = pd.ExcelWriter(dest_path + file_name, engine='xlsxwriter')\n",
    "df_summ_comb.to_excel(writer, 'Files_Summary', index=False)\n",
    "df_pre_cert.to_excel(writer, 'Prevals', index=False)\n",
    "df_err_cert.to_excel(writer, 'Errors', index=False)\n",
    "df_certfain.to_excel(writer, 'Certs', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To create a csv file, one file for each dataframe:\n",
    "# file_name = 'dataframe_name'+ timestr + '.csv'\n",
    "# df.to_csv(dest_path + file_name, index=False)\n",
    "\n",
    "# To create a copy of the file in a different directory:\n",
    "# shutil.copyfile(source path + file name, destination path + file name)\n",
    "\n",
    "# Information can also be extracted from emails saved to a drive/folder using ExtractMsg (https://github.com/mattgwwalker/msg-extractor):\n",
    "# import ExtractMsg\n",
    "# msg = ExtractMsg.Message('message_subject.msg')\n",
    "# print(msg.sender)\n",
    "# print(msg.date)\n",
    "# print(msg.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
