{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Comparison - OLS vs. kNN\n",
    "\n",
    "Comparing models is something data scientists do all the time. There's very rarely just one model that would be possible to run for a given situation, so learning to choose the best one is very important. In this exercise, the Ordinary Least Squares (i.e., linear regression) will be compared with k Nearest Neighbors (kNN).\n",
    "\n",
    "The data and linear regression model were built from the Multiple Linear Regression exercise at https://github.com/ChE99/projects/blob/master/Multiple%20Linear%20Regression.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Linear Regression\n",
    "\n",
    "#### 1. Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the FBI's 2013 New York crime dataset (skip first four rows).\n",
    "df_ny13 = pd.read_csv('https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/master/New_York_offenses/NEW_YORK-Offenses_Known_to_Law_Enforcement_by_City_2013%20-%2013tbl8ny.csv', skiprows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename applicable columns.\n",
    "df_ny13.rename(columns={'Population': 'population', 'Robbery': 'robbery', 'Property\\ncrime': 'property_crime'}, inplace=True)\n",
    "\n",
    "# Drop unnecessary variables.\n",
    "df_ny13_final = df_ny13.drop(['City', 'Rape\\n(revised\\ndefinition)1'], axis=1)\n",
    "\n",
    "# Drop last three rows with nulls.\n",
    "df_ny13_final = df_ny13_final[:-3]\n",
    "\n",
    "# Create function to remove commas and convert object type columns to numeric.\n",
    "cols_ny13 = df_ny13_final.columns[df_ny13_final.dtypes.eq('object')]\n",
    "convert_col = lambda col_obj: pd.to_numeric(col_obj.replace(',',''))\n",
    "df_ny13_final[cols_ny13] = df_ny13_final[cols_ny13].applymap(convert_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients: \n",
      " [  9.85497391e-05  -7.09633481e-10   1.17034383e+00]\n",
      "\n",
      "Intercept: \n",
      " 2.98340998967\n",
      "\n",
      "R-squared:\n",
      "0.731359253678\n"
     ]
    }
   ],
   "source": [
    "# Create features. Non-zero values of robbery will be coded as 1. \n",
    "df_ny13_final['population_squared'] = df_ny13_final['population'] * df_ny13_final['population']\n",
    "df_ny13_final['robbery_category'] = np.where(df_ny13_final['robbery']>0, 1, 0)\n",
    "\n",
    "# Drop rows with zeroes.\n",
    "df_ny13_final_nzpc = df_ny13_final[df_ny13_final['property_crime'] != 0]\n",
    "\n",
    "# Drop the rows containing the population outliers.\n",
    "df_ny13_or = df_ny13_final_nzpc[df_ny13_final_nzpc['population']<100000]\n",
    "\n",
    "# Set the variables.\n",
    "y_ny13_ppr_orlt = np.log(df_ny13_or['property_crime'])\n",
    "X_ny13_ppr_orlt = df_ny13_or[['population','population_squared', 'robbery_category']]\n",
    "\n",
    "# Fit the model.\n",
    "regr_ny13_ppr_orlt = linear_model.LinearRegression()\n",
    "regr_ny13_ppr_orlt.fit(X_ny13_ppr_orlt, y_ny13_ppr_orlt)\n",
    "\n",
    "# Show linear regression parameters.\n",
    "print('\\nCoefficients: \\n', regr_ny13_ppr_orlt.coef_)\n",
    "print('\\nIntercept: \\n', regr_ny13_ppr_orlt.intercept_)\n",
    "print('\\nR-squared:')\n",
    "print(regr_ny13_ppr_orlt.score(X_ny13_ppr_orlt, y_ny13_ppr_orlt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train and Test the Model\n",
    "\n",
    "##### a. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [ 6.44514237  3.28751279  3.37697186  3.52965185  4.45990579]\n",
      "\n",
      "\n",
      "Actual:\n",
      "322    6.347389\n",
      "50     4.060443\n",
      "250    4.595120\n",
      "264    3.496508\n",
      "15     3.218876\n",
      "Name: property_crime, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test samples. Use the outlier-removed, log-transformed dataset.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_tts_ny13, X_test_tts_ny13, y_train_tts_ny13, y_test_tts_ny13 = train_test_split(X_ny13_ppr_orlt, y_ny13_ppr_orlt, test_size=0.3)\n",
    "\n",
    "# Train the model.\n",
    "regr_tts_ny13 = linear_model.LinearRegression()\n",
    "lm_tts_ny13 = regr_tts_ny13.fit(X_train_tts_ny13, y_train_tts_ny13)\n",
    "\n",
    "# Make predictions on the test sample.\n",
    "predictions_tts_ny13 = regr_tts_ny13.predict(X_test_tts_ny13)\n",
    "\n",
    "# Compare predicted vs. actual.\n",
    "print('Predicted:', predictions_tts_ny13[0:5])\n",
    "print('\\n')\n",
    "print('Actual:')\n",
    "print(y_test_tts_ny13[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.689536394435\n"
     ]
    }
   ],
   "source": [
    "# Model score.\n",
    "print('Score:', lm_tts_ny13.score(X_test_tts_ny13, y_test_tts_ny13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. K-Folds Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validated scores: [ 0.71470059  0.70105702  0.70858824]\n",
      "Average score: 0.708115283492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Run the default three subsets, or folds, for cross validation.\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "scores_cv_ny13 = cross_val_score(lm_tts_ny13, X_ny13_ppr_orlt, y_ny13_ppr_orlt)\n",
    "\n",
    "# The score for each fold.\n",
    "print('Cross validated scores:', scores_cv_ny13)\n",
    "\n",
    "# Mean score.\n",
    "print('Average score:', scores_cv_ny13.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### B. KNN Regression \n",
    "\n",
    "#### 1. Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the train and test data from the linear regression model into the KNN model.\n",
    "from sklearn import neighbors\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors=5)\n",
    "knn_w = neighbors.KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "knn_tts_ny13 = knn.fit(X_train_tts_ny13, y_train_tts_ny13)\n",
    "knn_wtts_ny13 = knn_w.fit(X_train_tts_ny13, y_train_tts_ny13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Accuracy: 0.553825865141\n",
      "Weighted Accuracy: 0.478814128921\n"
     ]
    }
   ],
   "source": [
    "print('Unweighted Accuracy:', knn_tts_ny13.score(X_test_tts_ny13, y_test_tts_ny13))\n",
    "print('Weighted Accuracy:', knn_wtts_ny13.score(X_test_tts_ny13, y_test_tts_ny13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Accuracy: 0.641 (+/- 0.035)\n",
      "Weighted Accuracy: 0.554 (+/- 0.058)\n"
     ]
    }
   ],
   "source": [
    "# Run KNN cross validation.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(knn_tts_ny13, X_ny13_ppr_orlt, y_ny13_ppr_orlt, cv=3)\n",
    "print(\"Unweighted Accuracy: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n",
    "score_w = cross_val_score(knn_wtts_ny13, X_ny13_ppr_orlt, y_ny13_ppr_orlt, cv=3)\n",
    "print(\"Weighted Accuracy: %0.3f (+/- %0.3f)\" % (score_w.mean(), score_w.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A summary of the scores is as follows:\n",
    "\n",
    "Method|  OLS  |KNN UW | KNN W\n",
    "------|-------|-------|-------\n",
    "TTS   |  0.690|  0.554| 0.479\n",
    "CV    |  0.708|  0.641| 0.554"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a marked difference among the scores, and in both train/test split and cross validation, linear regression outperformed KNN. Since kNN is flexible, it is more susceptible to high noise - as opposed to linear regression, which is more rigid - and underperforms linear regression when the noise-to-signal ratio is high. kNN suffers from the curse of dimensionality, where prediction accuracy can significantly decrease as the number of predictors increases because of the data's distance from a test point. Although kNN can deal with nonlinearity, it cannot determine which predictors are important, or interpret the resulting predictors. Lastly, tuning K is critical to good performance.  \n",
    "\n",
    "Linear regression, on the other hand, has a fixed number of parameters and is computationally faster, but makes strong assumptions about the data. The algorithm may work well if the assumptions turn out to be correct, but it may perform badly if the assumptions are wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
